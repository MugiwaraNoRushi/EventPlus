{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from timelinemodule\timport TimelineModel\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docpath = \"../input_data_conllu/toronto_books_00.output\"\n",
    "gpunumber = 0\n",
    "outpath = \"../predictions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########   Parsing Conllu through PredPatt    ###########\n",
      "Number of sentences in the document: 10\n",
      "Number of event pairs considered: 72\n"
     ]
    }
   ],
   "source": [
    "## Dependency Graph object\n",
    "filename = docpath.split(\"/\")[-1]\n",
    "structures = get_structs(docpath)\n",
    "print(\"\\n###########   Parsing Conllu through PredPatt    ###########\")\n",
    "\n",
    "## Sentences\n",
    "struct_dict = extract_struct_dicts(structures)\n",
    "\n",
    "## A dataframe after processing the file through PredPatt and extracting\n",
    "## roots and spans of each predicate. \n",
    "df = extract_dataframe(docpath, structures)\n",
    "\n",
    "## Correct pred2_tokens as per the concatenated sentence\n",
    "df['pred2_token_mod'] = df.apply(lambda row: correct_pred2_tokens(row, struct_dict), axis=1)\n",
    "df['pred2_root_token_mod'] = df.apply(lambda row: correct_pred2_root(row, struct_dict), axis=1)\n",
    "#Convert tokens into list of numbers\n",
    "df['pred1_token_span'] = df['pred1_token'].map(lambda x: [int(y) for y in x.split(\"_\")])\n",
    "df['pred2_token_span'] = df['pred2_token_mod'].map(lambda x: [int(y) for y in x.split(\"_\")])\n",
    "\n",
    "## Extract X for model predictions\n",
    "X = extract_X(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and run the pairwise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########   Predicting Relative Timelines    ###########\n",
      "\n",
      "Relative Temporal Model configurations:\n",
      "Eventatt: param, Duratt: param, Relatt: param, Dropout: 0.5, Activation: relu, Binomial: True, concat_fine2dur: False, concat_dur2fine:False, fine_to_dur: False, dur_to_fine: False \n",
      "\n",
      "Relative timelines completed!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Load the best model\n",
    "squashed = True\n",
    "baseline=False\n",
    "loss_confidence = True\n",
    "cuda_device_num = gpunumber\n",
    "cuda_device_str = \"cuda:\" + str(cuda_device_num)\n",
    "model_path = \"../model/\"\n",
    "file_path = \"model_param_param_param_1_0_128_128_0_0_0_0_0.0_0.5_relu_1.pth\"\n",
    "\n",
    "tokens = file_path.split(\"_\")\n",
    "eventatt = tokens[1]\n",
    "duratt = tokens[2]\n",
    "relatt = tokens[3]\n",
    "concat_fine_to_dur = str2bool(tokens[-8])\n",
    "concat_dur_to_fine = str2bool(tokens[-7])\n",
    "fine_2_dur = str2bool(tokens[-6])\n",
    "dur_2_fine = str2bool(tokens[-5])\n",
    "weight = float(tokens[-4])\n",
    "drop = float(tokens[-3])\n",
    "activ = tokens[-2]\n",
    "bino_bool = str2bool(tokens[-1].split(\".\")[0])\n",
    "#coarse_size = int(tokens[-1].split(\".\")[0])\n",
    "print(\"\\n###########   Predicting Relative Timelines    ###########\")\n",
    "print(\"\\nRelative Temporal Model configurations:\")\n",
    "print(\"Eventatt: {}, Duratt: {}, Relatt: {}, Dropout: {}, Activation: {}, Binomial: {}, concat_fine2dur: {}, concat_dur2fine:{}, fine_to_dur: {}, dur_to_fine: {} \\n\".format(\n",
    "                                                                                                                        eventatt,\n",
    "                                                                                                                        duratt,\n",
    "                                                                                                                        relatt,\n",
    "                                                                                                                        drop,\n",
    "                                                                                                                        activ,\n",
    "                                                                                                                        bino_bool,\n",
    "                                                                                                                        concat_fine_to_dur,\n",
    "                                                                                                                        concat_dur_to_fine,\n",
    "                                                                                                                        fine_2_dur,\n",
    "                                                                                                       dur_2_fine))\n",
    "device = torch.device(cuda_device_str if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_model = TemporalModel(\n",
    "                            embedding_size=1024, \n",
    "                            duration_distr = bino_bool,\n",
    "                            elmo_class = ElmoEmbedder(options_file, weight_file, cuda_device=cuda_device_num),\n",
    "                            mlp_dropout = drop,\n",
    "                            mlp_activation= activ,\n",
    "                            tune_embed_size=256,\n",
    "                            event_attention=eventatt, \n",
    "                            dur_attention = duratt, \n",
    "                            rel_attention = relatt, \n",
    "                            concat_fine_to_dur  =concat_fine_to_dur,                      \n",
    "                            concat_dur_to_fine = concat_dur_to_fine,\n",
    "                            fine_to_dur = fine_2_dur,\n",
    "                            dur_to_fine = dur_2_fine,\n",
    "                            fine_squash = True,\n",
    "                            baseline=False,\n",
    "                            dur_MLP_sizes = [128], fine_MLP_sizes = [128],\n",
    "                            dur_output_size = 11, fine_output_size = 4,\n",
    "                            device= device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(model_path + file_path, map_location=cuda_device_str))\n",
    "best_model.to(device)\n",
    "\n",
    "p1_dur_yhat,p2_dur_yhat,fine_yhat,rel_yhat = predict_fine_dur_only(X, best_model)\n",
    "print(\"Relative timelines completed!!\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store predictions in the dataset\n",
    "df['pred1_duration'] = p1_dur_yhat.cpu().numpy()\n",
    "df['pred2_duration'] = p2_dur_yhat.cpu().numpy()\n",
    "df['b1'] = [b1 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['d1'] = [d1 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['e1'] = df['b1'] + df['d1']\n",
    "df['b2'] = [b2 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['d2'] = [d2 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['e2'] = df['b2'] + df['d2']\n",
    "df = df.drop(['d1', 'd2'], axis=1)\n",
    "df['sent_pred_id1'] = df['sentence_id_1'] + \" \" + df['pred1_root_token'].map(lambda x: str(x))\n",
    "df['sent_pred_id2'] = df['sentence_id_2'] + \" \" + df['pred2_root_token'].map(lambda x: str(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Timeilnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########   Creating document timelines    ###########\n",
      "Epoch: 1, Loss: 3.379361152648926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1320/5000 [00:04<00:13, 272.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1344, Converging-Loss: 0.9290573000907898\n"
     ]
    }
   ],
   "source": [
    "## Document Timelines\n",
    "pred_dict, num_preds, local_data = extract_preds(df)\n",
    "\n",
    "## Run Timeline Model on current docid's data\n",
    "model = TimelineModel(data = local_data,\n",
    "         num_preds = num_preds,\n",
    "        device=torch.device(\"cpu\"))\n",
    "\n",
    "print(\"###########   Creating document timelines    ###########\")\n",
    "pred_b1, pred_e1, pred_b2, pred_e2, pred_timeline  = model.fit(local_data, epochs=5000)\n",
    "\n",
    "preds_arr = local_data[['sent_pred_id1', 'sent_pred_id2']].values\n",
    "uniq_preds = np.unique(preds_arr.flatten())\n",
    "#print(uniq_preds)\n",
    "\n",
    "preds_text = extract_pred_text(uniq_preds, local_data)\n",
    "\n",
    "ans_df = pd.DataFrame(data=pred_timeline, \n",
    "                     columns=['start_pt', 'duration'])\n",
    "ans_df['sent_pred_id'] = uniq_preds\n",
    "ans_df['pred_text'] = preds_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/5000 [00:00<00:18, 265.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.9278492331504822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1376/5000 [00:05<00:12, 279.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1386, Converging-Loss: 0.5157613754272461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pred_b1, pred_e1, pred_b2, pred_e2, pred_timeline  = model.fit(local_data, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.5365e+00,  5.5718e-02],\n",
       "        [-1.5372e+00, -9.2672e-02],\n",
       "        [-6.1619e-01,  8.8976e-02],\n",
       "        [ 6.1581e-01, -1.0106e-01],\n",
       "        [ 6.0650e-01,  3.1116e-01],\n",
       "        [ 1.5392e+00, -7.6710e-02],\n",
       "        [-1.5393e+00,  1.1233e-01],\n",
       "        [ 1.5384e+00,  6.5114e-02],\n",
       "        [-1.5383e+00,  6.8459e-02],\n",
       "        [ 5.6968e-01, -9.1468e-02],\n",
       "        [ 5.6911e-01, -4.9486e-02],\n",
       "        [-5.6890e-01,  4.2131e-02],\n",
       "        [ 5.6595e-01,  6.6302e-02],\n",
       "        [-9.3672e-01, -3.1461e-04],\n",
       "        [ 7.8927e-01,  5.1339e-01],\n",
       "        [-7.8446e-01,  9.6793e-02],\n",
       "        [ 7.8430e-01,  9.4901e-02],\n",
       "        [ 7.8440e-01,  9.2749e-02],\n",
       "        [ 7.8448e-01,  8.0203e-02],\n",
       "        [ 6.3518e-01, -4.6026e-01],\n",
       "        [ 7.8437e-01,  1.0608e-01],\n",
       "        [-7.8389e-01, -3.6686e-01],\n",
       "        [ 6.2765e-01,  9.7026e-02],\n",
       "        [ 6.2440e-01,  1.1565e-01],\n",
       "        [-6.2552e-01, -1.1014e-01],\n",
       "        [-6.2517e-01,  1.1213e-01],\n",
       "        [-6.2636e-01, -1.0781e-01],\n",
       "        [-6.2187e-01,  1.2996e-01],\n",
       "        [-6.1676e-01, -1.5168e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp)",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
